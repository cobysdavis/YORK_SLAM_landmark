import numpy as np
#!/usr/bin/env python
import cv2
from matplotlib import pyplot as plt
from random import randint
import rospy
from std_msgs.msg import Float64MultiArray
from std_msgs.msg import Bool

def output4Matches(good_matches):
	list=[]
	prev=[]
	while len(list)<4:
		x=randint(0,len(good_matches))
		if not isPrev(prev,x):
			list.append(good_matches[x])
		prev.append(x)
	return list

def isPrev(list,x):
	for l in list:
		if l==x:
			return True
	return False


def create_same_points(points,kp1,kp2):
	list=[]
	list.append([])
	list.append([])
	for p in points:
		list[0].append(kp1[p.queryIdx].pt)
		list[1].append(kp2[p.trainIdx].pt)
	a=np.float32(list[0])
	b=np.float32(list[1])
	list2=[]
	list2.append(a)
	list2.append(b)
	return list2
	

def drawMatches(img1, img2,list1,list2):
    # Create a new output image that concatenates the two images together
    # (a.k.a) a montage
    rows1 = img1.shape[0]
    cols1 = img1.shape[1]
    rows2 = img2.shape[0]
    cols2 = img2.shape[1]

    out = np.zeros((max([rows1,rows2]),cols1+cols2,3), dtype='uint8')

    # Place the first image to the left
    out[:rows1,:cols1] = np.dstack([img1, img1, img1])

    # Place the next image to the right of it
    out[:rows2,cols1:] = np.dstack([img2, img2, img2])

    # For each pair of points we have between both images
    # draw circles, then connect a line between them
    for i in range(0,4):
	
        # x - columns
        # y - rows
        (x1,y1) = list1[i]
        (x2,y2) = list2[i]
	print str((x1,y1))
	print str((x2,y2))
        # Draw a small circle at both co-ordinates
        # radius 4
        # colour blue
        # thickness = 1
        cv2.circle(out, (int(x1),int(y1)), 8, (255, 0, 0), 7)   
        cv2.circle(out, (int(x2)+cols1,int(y2)), 8, (255, 0, 0), 7)

        # Draw a line in between the two points
        # thickness = 1
        # colour blue
        cv2.line(out, (int(x1),int(y1)), (int(x2)+cols1,int(y2)), (255, 0, 0), 8)


    # Show the image
    #cv2.imshow('Matched Features', out)
    cv2.waitKey(0)
    cv2.destroyWindow('Matched Features')

    # Also return the image if you'd like a copy
    return out

def publishTransform(data):
	img1 = cv2.imread('query.jpg',0) # queryImage
	img2 = cv2.imread('logo.jpg',0) # trainImage
	threshhold=0.3

	# Initiate SIFT detector
	#sift = cv2.xfeatures2d.SIFT_create()
	sift=cv2.SIFT()
	print "post sift"
	# find the keypoints and descriptors with SIFT
	kp1, des1 = sift.detectAndCompute(img1,None)
	print "post sift"
	kp2, des2 = sift.detectAndCompute(img2,None)
	print "post sift"

	# BFMatcher with default params
	bf = cv2.BFMatcher()
	matches = bf.knnMatch(des1,des2, k=2)

	# Apply ratio test
	good = []
	for m,n in matches:
	    if m.distance < threshhold*n.distance:
		good.append([m])
	good2=[]
	for m,n in matches:
	    if m.distance < threshhold*n.distance:
		good2.append(m)


	
	# cv2.drawMatchesKnn expects list of lists as matches.
	img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=2)

	#plt.imshow(img3),plt.show()

	#output 4 necessary matches
	matching_points=output4Matches(good2)

	point_list=create_same_points(matching_points,kp1,kp2)

	#draw 4  matching points
	img4 = drawMatches(img1,img2,point_list[0],point_list[1])

	plt.imshow(img4),plt.show()

	#create transfomration matrix
	M = cv2.getPerspectiveTransform(point_list[0],point_list[1])
	print M
	#matrix=Float64MultiArray()
	for i in range(0,2):
		matrix.data.append(M[0][i])
	for i in range(3,5):
		matrix.data.append(M[1][i])
	for i in range(6,8):
		matrix.data.append(M[2][i])
	
	pub.publish(matrix)
	#apply to query Image to see if matrix is correct

	dst1 = cv2.warpPerspective(img1,M,(3000,3000))
	plt.subplot(121),plt.imshow(img1),plt.title('Input')
	plt.subplot(122),plt.imshow(dst1),plt.title('Output')
	plt.show()



if __name__=='__main__' :
	rospy.init_node('transformatioMatrix')
	pub=rospy.Publisher('matrix',Float64MultiArray,queue_size=10)
	sub=rospy.Subscriber('pictureTaken',Bool,publishTransform)
	rospy.spin()


